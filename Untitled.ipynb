{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import dlib\n",
    "from collections import Counter\n",
    "from object_detection import yoloV3Detect\n",
    "from landmark_models import *\n",
    "from face_spoofing import *\n",
    "from headpose_estimation import *\n",
    "from face_detection import get_face_detector, find_faces\n",
    "\n",
    "################################################ Setup ######################################################\n",
    "\n",
    "# Initialize face recognition\n",
    "l = os.listdir('student_db')\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "for image in l:\n",
    "    obama_image = face_recognition.load_image_file('student_db/' + image)\n",
    "    obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "    known_face_encodings.append(obama_face_encoding)\n",
    "    known_face_names.append(image.split('.')[0])\n",
    "\n",
    "# Load models\n",
    "h_model = load_hp_model('models/Headpose_customARC_ZoomShiftNoise.hdf5')\n",
    "face_model = get_face_detector()\n",
    "predictor = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Global variables for video capture\n",
    "video_capture = None\n",
    "process_this_frame = False\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "no_of_frames = [0] * 8\n",
    "flag = True\n",
    "\n",
    "################################################ MONITORING FUNCTION #####################################################\n",
    "def start_monitoring():\n",
    "    global process_this_frame, flag, video_capture\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    if not video_capture.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Failed to access the camera.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        process_this_frame = not process_this_frame\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            messagebox.showerror(\"Error\", \"Failed to read from the camera.\")\n",
    "            break\n",
    "\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        frame2 = frame.copy()\n",
    "        frame3 = frame.copy()\n",
    "        report = np.zeros((frame.shape[0], 400, 3), np.uint8)\n",
    "\n",
    "        if process_this_frame:\n",
    "            try:\n",
    "                ##### Object Detection #####\n",
    "                try:\n",
    "                    fboxes, fclasses = yoloV3Detect(small_frame)\n",
    "                    to_detect = ['person', 'laptop', 'cell phone', 'book', 'tv']\n",
    "                    detected_items = [fclasses[i] for i in range(len(fclasses)) if fclasses[i] in to_detect]\n",
    "                    count_items = Counter(detected_items)\n",
    "                except:\n",
    "                    count_items = {'person': 0, 'laptop': 0, 'cell phone': 0, 'book': 0, 'tv': 0}\n",
    "\n",
    "                # Check for banned objects\n",
    "                multiple_people = count_items['person'] != 1\n",
    "                banned_objects_detected = count_items['laptop'] > 0 or count_items['cell phone'] > 0 or count_items['book'] > 0 or count_items['tv'] > 0\n",
    "                \n",
    "                faces = find_faces(small_frame, face_model)\n",
    "                face_detected = len(faces) > 0\n",
    "\n",
    "                name = \"Unknown\"\n",
    "                if face_detected:\n",
    "                    (left, top, right, bottom) = faces[0]\n",
    "                    face_locations = [(top, right, bottom, left)]\n",
    "                    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "                    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "                    if face_encodings:\n",
    "                        matches = face_recognition.compare_faces(known_face_encodings, face_encodings[0])\n",
    "                        face_distances = face_recognition.face_distance(known_face_encodings, face_encodings[0])\n",
    "                        best_match_index = np.argmin(face_distances)\n",
    "                        name = known_face_names[best_match_index] if matches[best_match_index] else \"Unknown\"\n",
    "\n",
    "                ##### Head Pose Estimation #####\n",
    "                unusual_head_pose = False\n",
    "                if face_detected:\n",
    "                    oAnglesNp, _ = headpose_inference(h_model, frame2, faces[0])\n",
    "                    unusual_head_pose = round(oAnglesNp[0], 1) not in [0.0, -1.0] and round(oAnglesNp[1], 0) not in [0.0, 1.0]\n",
    "\n",
    "                ##### Face Spoofing Detection #####\n",
    "                spoof_detected = False\n",
    "                if face_detected:\n",
    "                    spoof_detected = detect_spoof(frame2, faces[0])\n",
    "\n",
    "                ##### Mouth Activity Detection #####\n",
    "                mouth_open = False\n",
    "                if face_detected:\n",
    "                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    face_dlib = dlib.rectangle(left * 4, top * 4, right * 4, bottom * 4)\n",
    "                    facial_landmarks = predictor(gray, face_dlib)\n",
    "                    mouth_ratio = get_mouth_ratio([60, 62, 64, 66], frame2, facial_landmarks)\n",
    "                    mouth_open = mouth_ratio > 0.1\n",
    "\n",
    "                ##### Report Display #####\n",
    "                cv2.putText(report, f\"Number of people detected: {count_items['person']}\", (10, 40), font, 0.8, (0, 255, 0), 2)\n",
    "                cv2.putText(report, f\"Banned objects detected: {banned_objects_detected}\", (10, 80), font, 0.8, (0, 255, 0), 2)\n",
    "                cv2.putText(report, f\"Face Recognized: {name}\", (10, 120), font, 0.8, (0, 255, 0), 2)\n",
    "                cv2.putText(report, f\"Mouth Open: {mouth_open}\", (10, 160), font, 0.8, (0, 255, 0), 2)\n",
    "                cv2.putText(report, f\"Head Pose: {'Unusual' if unusual_head_pose else 'Looking at screen'}\", (10, 200), font, 0.8, (0, 255, 0), 2)\n",
    "                cv2.putText(report, f\"Spoof Face detected: {spoof_detected}\", (10, 240), font, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "                horizontalAppendedImg = np.hstack((frame3, report))\n",
    "                cv2.imshow(\"Proctoring Window\", horizontalAppendedImg)\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "################################################ TKINTER GUI ################################################\n",
    "\n",
    "def create_window():\n",
    "    window = tk.Tk()\n",
    "    window.title(\"Real-Time Exam Monitoring System\")\n",
    "    window.geometry(\"400x300\")\n",
    "\n",
    "    label = tk.Label(window, text=\"Real-Time Exam Monitoring System\", font=(\"Arial\", 16))\n",
    "    label.pack(pady=20)\n",
    "\n",
    "    start_button = tk.Button(window, text=\"Start Monitoring\", command=start_monitoring, font=(\"Arial\", 14), bg=\"green\", fg=\"white\")\n",
    "    start_button.pack(pady=30)\n",
    "\n",
    "    window.mainloop()\n",
    "\n",
    "create_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedc8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc2023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
